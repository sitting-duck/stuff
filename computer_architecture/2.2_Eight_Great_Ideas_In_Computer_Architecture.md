
### Design for Moores Law
The one constant for computer designers is rapid change, which is driven largely by Moores Law. Integrated Circuit resources double every 18-24 months. 
Moores Law results from a 1965 prediction of such growth in IC capacity made by Gordon Moore, one of the founders of Intel. As computer designs can take years, the rethe resources available per chip can easily double or quadruple between the start and finish of the project. Like a skeet shooter, computer architects must anticipate where the technology will be when the design finishes rather than design for where it starts. We use an up and to the right Moores Law graph to represent designing for rapid change.

### Use Abstraction to Simplify Design
abstractions simplify the lower levels and allow us to design at a higher level

### Make the Common Case Fast
Optimize the Common case, 

### Performance Via Perallelism 
for example, jet engines 

### Performance Via Pipelining
A particular patter of parallism is so prevalent in computer architecture that it merits its own name, pipelining. Which moves multiple operations through hardwware units that each do a piece of an operation, akin to water flowing through a pipeline

### Performance Via Prediction
It can be faster on average to guess and start working rather than wait until you know for sure, assuming that the mechanism to recover from a misprediction is not too expensive and your prediction is relatively accurate. 

### Hierarchy of Memories
programmers want the memory to be fast, large and cheap, as memory speed often shapes performanc, capacity limits the size of problems that can be solved, and the cost of memory today is often the majority of computer cost. Architects have found that they can address conflicting demands of fast, large, and cheap memory with a hierarchy of memories, with the fastest, smallest and most expensive memory per bit at the top of the hierarchy and the slowest largest and cheapest per bit at the bottom. Caches give the programmer the illusion that main memory is almost as fast as the top of the hierarchy and nearly as big and cheap as the bottom of the heirarchy. We use a layered triangle icon to represent the memory hierarchy. 
The shape indicates speed, cost, and size: the closer to the to, the faster and more expensive per bit the memory. the wider the base of the layer, the bigger the memory. 

### Dependability Via Redundancy
Computers not only need to be fast, they need to be dependable. Since any physical device can fail, we make systems dependable by including redundant components that can take over whena failure occurs and to delp detect failures. We use the tractor trailor as a metaphor, since the dual tires on each side of its rear axles allow the truck to continue driving even when one tire fails.

